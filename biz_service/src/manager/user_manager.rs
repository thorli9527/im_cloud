// === Imports ===
// å¼•å…¥æ‰€éœ€æ ‡å‡†åº“ã€ç¬¬ä¸‰æ–¹åº“å’Œé¡¹ç›®å†…æ¨¡å—
use std::collections::HashSet;
use std::sync::atomic::{AtomicBool, Ordering};
use std::sync::Arc;
use std::time::Duration;

use dashmap::{DashMap, DashSet}; // é«˜æ€§èƒ½å¹¶å‘å“ˆå¸Œè¡¨
use deadpool_redis::{
    redis::{from_redis_value, AsyncCommands, RedisResult},
    Pool,
};
use dashmap::mapref::multiple::RefMulti;
use mongodb::Database;
use once_cell::sync::OnceCell;
use redis::cmd;
use serde::{Deserialize, Serialize};
use tokio::sync::Notify;
use tokio::time::sleep;

use common::errors::AppError;
use crate::biz_service::client_service::ClientService;
use crate::manager::init;

// === Constants ===
const USER_ONLINE_TTL_SECS: u64 = 30;  // ç”¨æˆ·åœ¨çº¿ TTL
const STREAM_KEY: &str = "user:events";  // Redis Stream çš„ key
const CONSUMER_GROUP: &str = "user_events_group"; // æ¶ˆè´¹è€…ç»„åç§°
const CONSUMER_NAME: &str = "user_manager"; // æ¶ˆè´¹è€…å®ä¾‹åç§°
const SHARD_COUNT: usize = 8; // æœ¬åœ°ç¼“å­˜åˆ†ç‰‡æ•°é‡
const MAX_CLEAN_COUNT: usize = 100; // æ¸…ç†æ—¶æœ€å¤šåˆ é™¤çš„ç©ºç¾¤ç»„æ•°

// === ç”¨æˆ·äº‹ä»¶æšä¸¾ ===
// ç”¨äº Redis Stream æ¶ˆæ¯ä¼ é€’çš„äº‹ä»¶æ¨¡å‹
#[derive(Debug, Deserialize, Serialize)]
#[serde(tag = "type", rename_all = "snake_case")]
enum UserEvent {
    GroupLeave { group_id: String, user_id: String },
    GroupJoin { group_id: String, user_id: String },
    Online { user_id: String },
    Offline { user_id: String },
}

// === åˆ†ç‰‡ç¾¤ç»„ç»“æ„ ===
#[derive(Debug, Clone)]
struct ShardedGroupMap {
    shards: Arc<Vec<DashMap<String, DashSet<String>>>>, // æ¯ä¸ªç¾¤ç»„æ˜¯ä¸€ä¸ª DashSet
}

impl ShardedGroupMap {
    pub fn new() -> Self {
        let shards = Arc::new((0..SHARD_COUNT).map(|_| DashMap::new()).collect());
        Self { shards }
    }

    // å“ˆå¸Œå‡½æ•°ï¼Œç”¨äºå®šä½ shard
    fn hash(key: &str) -> usize {
        fxhash::hash32(key.as_bytes()) as usize % SHARD_COUNT
    }

    // è·å–åªè¯»å¼•ç”¨
    pub fn get(&self, key: &str) -> Option<dashmap::mapref::one::Ref<String, DashSet<String>>> {
        self.shards[Self::hash(key)].get(key)
    }

    // è·å–å¯å˜å¼•ç”¨
    pub fn get_mut(&self, key: &str) -> Option<dashmap::mapref::one::RefMut<String, DashSet<String>>> {
        self.shards[Self::hash(key)].get_mut(key)
    }

    // è·å–æˆ–æ’å…¥ entry
    pub fn entry(&self, key: String) -> dashmap::mapref::entry::Entry<String, DashSet<String>> {
        self.shards[Self::hash(&key)].entry(key)
    }

    // åˆ é™¤ç¾¤ç»„ç¼“å­˜
    pub fn remove(&self, key: &str) {
        self.shards[Self::hash(key)].remove(key);
    }

    // è¿­ä»£æ‰€æœ‰ç¼“å­˜é¡¹
    pub fn iter(&self) -> impl Iterator<Item = RefMulti<String, DashSet<String>>> + '_ {
        self.shards.iter().flat_map(|shard| shard.iter())
    }
}

// === Redis ç”¨æˆ·ç®¡ç†å™¨ ===
#[derive(Clone, Debug)]
pub struct RedisUserManager {
    redis_pool: Pool, // Redis è¿æ¥æ± 
    local_online_shards: Arc<Vec<DashMap<String, ()>>>, // æœ¬åœ°åœ¨çº¿ç”¨æˆ·ç¼“å­˜åˆ†ç‰‡
    local_group_map: ShardedGroupMap, // æœ¬åœ°ç¾¤ç»„æˆå‘˜ç¼“å­˜
    is_initialized: Arc<AtomicBool>, // æ˜¯å¦åˆå§‹åŒ–å®Œæˆ
    init_notify: Arc<Notify>, // åˆå§‹åŒ–å®Œæˆé€šçŸ¥å™¨
    node_id: usize, // å½“å‰èŠ‚ç‚¹ç¼–å·
    node_total: usize, // æ€»èŠ‚ç‚¹æ•°ï¼ˆç”¨äºåˆ†ç‰‡è´£ä»»åˆ¤å®šï¼‰
    use_local_cache: bool, // æ˜¯å¦ä½¿ç”¨æœ¬åœ°ç¼“å­˜åŠ é€Ÿ
}

impl RedisUserManager {
    // åˆå§‹åŒ–æ–°å®ä¾‹ï¼Œå¯åŠ¨åå°ä»»åŠ¡ï¼šåŠ è½½ç¼“å­˜ã€äº‹ä»¶ç›‘å¬ã€å®šæ—¶æ¸…ç†
    pub fn new(redis_pool: Pool, node_id: usize, node_total: usize, use_local_cache: bool) -> Self {
        let online_shards = (0..SHARD_COUNT).map(|_| DashMap::new()).collect();
        let manager = Self {
            redis_pool,
            local_online_shards: Arc::new(online_shards),
            local_group_map: ShardedGroupMap::new(),
            is_initialized: Arc::new(AtomicBool::new(false)),
            init_notify: Arc::new(Notify::new()),
            node_id,
            node_total,
            use_local_cache,
        };

        // åå°åˆå§‹åŒ–ä»»åŠ¡
        let manager_clone = manager.clone();
        tokio::spawn(async move {
            if manager_clone.use_local_cache {
                if let Err(e) = manager_clone.initialize_from_redis().await {
                    eprintln!("[RedisUserManager] åˆå§‹åŒ–å¤±è´¥: {:?}", e);
                }
            }
            if let Err(e) = manager_clone.start_stream_event_consumer().await {
                eprintln!("[RedisUserManager] æ¶ˆè´¹å™¨å¯åŠ¨å¤±è´¥: {:?}", e);
            }
            manager_clone.is_initialized.store(true, Ordering::SeqCst);
            manager_clone.init_notify.notify_waiters();
            println!("[RedisUserManager] âœ… åˆå§‹åŒ–å®Œæˆ");
        });

        // å¯åŠ¨ç©ºç¾¤ç»„æ¸…ç†å™¨
        let cleaner = manager.clone();
        tokio::spawn(async move {
            loop {
                sleep(Duration::from_secs(300)).await;
                if let Err(e) = cleaner.clean_empty_groups().await {
                    eprintln!("[RedisUserManager] âŒ æ¸…ç†ç©ºç¾¤ç»„å¤±è´¥: {:?}", e);
                }
            }
        });

        // æ³¨å†Œå…¨å±€å•ä¾‹
        manager.init(manager.clone());
        manager
    }

    // è·å–ç”¨æˆ·åˆ†ç‰‡
    fn get_online_shard(&self, user_id: &str) -> &DashMap<String, ()> {
        let hash = fxhash::hash32(user_id.as_bytes());
        &self.local_online_shards[(hash as usize) % SHARD_COUNT]
    }

    // åˆ¤å®šæ˜¯å¦ç”±å½“å‰èŠ‚ç‚¹è´Ÿè´£ç®¡ç†è¯¥ç”¨æˆ·
    fn is_responsible(&self, user_id: &str) -> bool {
        let hash = fxhash::hash32(user_id.as_bytes()) as usize;
        (hash % self.node_total) == self.node_id
    }

    // ç­‰å¾…åˆå§‹åŒ–å®Œæˆï¼ˆå¼‚æ­¥ï¼‰
    pub async fn wait_until_ready(&self) {
        if !self.is_ready() {
            self.init_notify.notified().await;
        }
    }

    // æ£€æŸ¥æ˜¯å¦åˆå§‹åŒ–å®Œæˆ
    pub fn is_ready(&self) -> bool {
        self.is_initialized.load(Ordering::SeqCst)
    }

    // è·å–æŸä¸ªç¾¤ç»„çš„æ‰€æœ‰æˆå‘˜
    pub fn get_group_members(&self, group_id: &str) -> Vec<String> {
        self.local_group_map.get(group_id)
            .map(|set| set.iter().map(|id| id.clone()).collect())
            .unwrap_or_default()
    }

    // è®¾ç½®ç”¨æˆ·ä¸Šçº¿ï¼ˆå¸¦äº‹ä»¶å¹¿æ’­ï¼‰
    pub async fn online(&self, user_id: &str) -> Result<(), AppError> {
        if self.use_local_cache && self.is_responsible(user_id) {
            self.get_online_shard(user_id).insert(user_id.to_string(), ());
        }
        let mut conn = self.redis_pool.get().await?;
        let _:()=conn.set_ex(format!("online:user:{}", user_id), "1", USER_ONLINE_TTL_SECS).await?;
        let payload = serde_json::to_string(&UserEvent::Online { user_id: user_id.to_string() })?;
        let _:()=conn.xadd(STREAM_KEY, "*", &[("payload", &payload)]).await?;
        Ok(())
    }

    // è®¾ç½®ç”¨æˆ·ä¸‹çº¿
    pub async fn offline(&self, user_id: &str) -> Result<(), AppError> {
        if self.use_local_cache && self.is_responsible(user_id) {
            self.get_online_shard(user_id).remove(user_id);
        }
        let mut conn = self.redis_pool.get().await?;
        let _:()=conn.del(format!("online:user:{}", user_id)).await?;
        let payload = serde_json::to_string(&UserEvent::Offline { user_id: user_id.to_string() })?;
        let _:()=conn.xadd(STREAM_KEY, "*", &[("payload", &payload)]).await?;
        Ok(())
    }

    // åˆ¤æ–­ç”¨æˆ·æ˜¯å¦åœ¨çº¿
    pub async fn is_online(&self, user_id: &str) -> Result<bool, AppError> {
        if self.use_local_cache && self.is_responsible(user_id) && self.get_online_shard(user_id).contains_key(user_id) {
            return Ok(true);
        }
        let mut conn = self.redis_pool.get().await?;
        Ok(conn.exists(format!("online:user:{}", user_id)).await?)
    }

    // æ·»åŠ ç”¨æˆ·è‡³ç¾¤ç»„å¹¶å¹¿æ’­äº‹ä»¶
    pub async fn add_to_group(&self, group_id: &str, user_id: &str) -> Result<(), AppError> {
        let mut conn = self.redis_pool.get().await?;
        let _:()=conn.sadd(format!("group:{}", group_id), user_id).await?;
        self.local_group_map.entry(group_id.to_string()).or_insert_with(DashSet::new).insert(user_id.to_string());
        let payload = serde_json::to_string(&UserEvent::GroupJoin { group_id: group_id.to_string(), user_id: user_id.to_string() })?;
        let _:()=conn.xadd(STREAM_KEY, "*", &[("payload", &payload)]).await?;
        Ok(())
    }

    // ä»ç¾¤ç»„ä¸­ç§»é™¤ç”¨æˆ·
    pub async fn remove_from_group(&self, group_id: &str, user_id: &str) -> Result<(), AppError> {
        let mut conn = self.redis_pool.get().await?;
        let _:()=conn.srem(format!("group:{}", group_id), user_id).await?;
        if let Some(mut group) = self.local_group_map.get_mut(group_id) {
            group.remove(user_id);
        }
        let payload = serde_json::to_string(&UserEvent::GroupLeave { group_id: group_id.to_string(), user_id: user_id.to_string() })?;
        let _:()=conn.xadd(STREAM_KEY, "*", &[("payload", &payload)]).await?;
        Ok(())
    }

    // æ¸…ç†ç©ºç¾¤ç»„
    pub async fn clean_empty_groups(&self) -> Result<(), AppError> {
        let mut conn = self.redis_pool.get().await?;
        let mut to_delete = Vec::with_capacity(MAX_CLEAN_COUNT);
        let mut scanned = 0;

        for entry in self.local_group_map.iter() {
            if to_delete.len() >= MAX_CLEAN_COUNT { break; }
            scanned += 1;
            if entry.value().is_empty() {
                to_delete.push(entry.key().clone());
            }
        }

        for group_id in &to_delete {
            let _:()=conn.del(format!("group:{}", group_id)).await?;
            self.local_group_map.remove(group_id);
            println!("[RedisUserManager] ğŸ§¹ æ¸…ç†ç©ºç¾¤ç»„: {}", group_id);
        }

        println!("[RedisUserManager] âœ… æ¸…ç†å®Œæˆ: {} / {}", to_delete.len(), scanned);
        Ok(())
    }

    // ä» Redis åˆå§‹åŒ–æœ¬åœ°åœ¨çº¿çŠ¶æ€å’Œç¾¤ç»„æ˜ å°„
    pub async fn initialize_from_redis(&self) -> Result<(), AppError> {
        let mut conn = self.redis_pool.get().await?;
        let mut cursor = 0u64;
        loop {
            let (next_cursor, keys): (u64, Vec<String>) = cmd("SCAN")
                .arg(cursor).arg("MATCH").arg("online:user:*").arg("COUNT").arg(100)
                .query_async(&mut conn).await?;
            for key in keys {
                if let Some(user_id) = key.strip_prefix("online:user:") {
                    if self.is_responsible(user_id) {
                        self.get_online_shard(user_id).insert(user_id.to_string(), ());
                    }
                }
            }
            if next_cursor == 0 { break; }
            cursor = next_cursor;
        }
        self.reload_group_map().await
    }

    // é‡æ–°åŠ è½½ç¾¤ç»„æ˜ å°„
    pub async fn reload_group_map(&self) -> Result<(), AppError> {
        let mut conn = self.redis_pool.get().await?;
        let mut cursor = 0u64;
        loop {
            let (next_cursor, keys): (u64, Vec<String>) = cmd("SCAN")
                .arg(cursor).arg("MATCH").arg("group:*").arg("COUNT").arg(100)
                .query_async(&mut conn).await?;
            for key in &keys {
                if let Some(group_id) = key.strip_prefix("group:") {
                    let members: HashSet<String> = conn.smembers(&key).await.unwrap_or_default();
                    let group = self.local_group_map.entry(group_id.to_string()).or_insert_with(DashSet::new);
                    for user_id in members {
                        group.insert(user_id);
                    }
                }
            }
            if next_cursor == 0 { break; }
            cursor = next_cursor;
        }
        println!("[RedisUserManager] âœ… ç¾¤ç»„æ˜ å°„å·²é‡æ–°åŠ è½½");
        Ok(())
    }

    // å¯åŠ¨ Stream æ¶ˆè´¹å™¨ï¼ˆå¾…è¡¥å……é€»è¾‘ï¼‰
    pub async fn start_stream_event_consumer(&self) -> Result<(), AppError> {
        Ok(())
    }

    // æ³¨å†Œä¸ºå…¨å±€å•ä¾‹
    fn init(&self, instance: RedisUserManager) {
        INSTANCE.set(Arc::new(instance)).expect("INSTANCE already initialized");
    }

    // è·å–å…¨å±€å®ä¾‹
    pub fn get() -> Arc<Self> {
        INSTANCE.get().expect("INSTANCE is not initialized").clone()
    }
}

// å•ä¾‹é™æ€å˜é‡
static INSTANCE: OnceCell<Arc<RedisUserManager>> = OnceCell::new();
