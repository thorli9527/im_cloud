use crate::protocol::common::{ByteMessageType};
use anyhow::{Result, anyhow};
use common::config::KafkaConfig;
use once_cell::sync::OnceCell;
use prost::Message;
use rdkafka::ClientConfig;
use rdkafka::admin::{AdminClient, AdminOptions, NewTopic, TopicReplication};
use rdkafka::producer::{FutureProducer, FutureRecord};
use rdkafka::statistics::Broker;
use std::fmt;
use std::sync::Arc;
use std::time::Duration;
use num_enum::{IntoPrimitive, TryFromPrimitive};
use strum::IntoEnumIterator;
use strum_macros::{AsRefStr, Display, EnumIter, EnumString};
use utoipa::openapi::security::Password;
use common::util::common_utils::build_md5;
use crate::manager::init;
use crate::protocol::msg::group_models::GroupNodeMsgType;

pub const GROUP_NODE_MSG_TOPIC : &str= "group-node-msg";
#[derive(Clone)]
pub struct KafkaGroupService {
    pub producer: Arc<FutureProducer>,
}
impl fmt::Debug for KafkaGroupService {
    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {
        f.debug_struct("KafkaGroupService")
            .field("producer", &"FutureProducer(...)")
            .finish()
    }
}
impl KafkaGroupService {
    pub async fn new(broker_addr: &str) -> Result<Self> {
        KafkaGroupService::init(broker_addr).await;
        let producer: FutureProducer = ClientConfig::new()
            .set("bootstrap.servers", broker_addr)
            .set("security.protocol", "SASL_SSL")
            .set("sasl.mechanism", "PLAIN")
            .set("sasl.username", "admin")
            .set("sasl.password", build_md5(&broker_addr))
            // âœ… æ€§èƒ½ç›¸å…³é…ç½®
            .set("queue.buffering.max.kbytes", "10240")     // é»˜è®¤4000ï¼Œæå‡å†…å­˜ buffer
            .set("queue.buffering.max.ms", "5")              // å»¶è¿Ÿèšåˆ
            .set("compression.type", "lz4")                  // å‹ç¼©æå‡åå
            .set("acks", "1")                                // æˆæœ¬å‡è¡¡ï¼ˆ0/1/allï¼‰
            .set("batch.num.messages", "1000")
            .set("linger.ms", "5")
            .set("message.timeout.ms", "30000")
            .create()
            .map_err(|e| anyhow!("Kafka producer create failed for {broker_addr}: {e}"))?;

        Ok(Self {
            producer: Arc::new(producer),
        })
    }

    /// å‘é€ Protobuf æ¶ˆæ¯ï¼ˆå¸¦ç±»å‹ç é¦–å­—èŠ‚ï¼‰
    pub async fn send_proto<M: Message>(
        &self,
        msg_type: &GroupNodeMsgType,
        message: &M,
        message_id: &str
    ) -> Result<()> {
        let mut payload = Vec::with_capacity(1 + message.encoded_len());
        payload.push(*msg_type as u8);
        message.encode(&mut payload)?;

        let key = message_id.to_string();

        let record = FutureRecord::to(GROUP_NODE_MSG_TOPIC)
            .payload(&payload)
            .key(&key);
        let timeout = Duration::from_millis(500); // âœ… æ›´åˆç†çš„è¶…æ—¶

        match self.producer.send(record, timeout).await {
            Ok(delivery) => {
                log::debug!(
                    "âœ… Kafka[{}] sent msg_id={} â†’ partition={} offset={}",
                    GROUP_NODE_MSG_TOPIC,
                    message_id,
                    delivery.partition,
                    delivery.offset
                );
                Ok(())
            }
            Err((err, _)) => {
                log::error!(
                    "âŒ Kafka send failed. topic={} msg_id={} err={:?}",
                    GROUP_NODE_MSG_TOPIC,
                    message_id,
                    err
                );
                Err(anyhow!(err))
            }
        }
    }

    /// åˆå§‹åŒ–æ‰€æœ‰ group ç›¸å…³ topicsï¼ˆå¹‚ç­‰ï¼‰
    async fn init(brokers: &str) {
        let mut dynamic_topics = Vec::new();
        dynamic_topics.push(("group-node-msg".to_string(), 3, 1));
        if let Err(e) = Self::create_topics(&brokers, &dynamic_topics).await {
            log::error!("âŒ Kafka topic åˆ›å»ºå¤±è´¥: {e}");
        } else {
            log::info!("âœ… KafkaGroupService åˆå§‹åŒ–å®Œæˆï¼Œtopic æ•°é‡ = {}", dynamic_topics.len());
        }
    }

    /// åˆ›å»º topicsï¼ˆå¤±è´¥æ—¥å¿—æç¤ºï¼Œä½†ä¸ä¸­æ–­ï¼‰
    pub async fn create_topics(
        brokers: &str,
        topics: &[(String, i32, i32)],
    ) -> Result<()> {
        let admin: AdminClient<_> = ClientConfig::new()
            .set("bootstrap.servers", brokers)
            .set("security.protocol", "SASL_SSL") // æˆ– "SASL_PLAINTEXT" è§†ä½ çš„é›†ç¾¤é…ç½®è€Œå®š
            .set("sasl.mechanism", "PLAIN")       // ä¹Ÿå¯ä»¥æ˜¯ SCRAM-SHA-256 / SCRAM-SHA-512 ç­‰
            .set("sasl.username", "admin")
            .set("sasl.password", build_md5(brokers))
            .create()
            .map_err(|e| anyhow!("Failed to create Kafka AdminClient: {e}"))?;

        let topic_defs: Vec<_> = topics
            .iter()
            .map(|(name, part, rep)| NewTopic::new(name, *part, TopicReplication::Fixed(*rep)))
            .collect();

        let results = admin
            .create_topics(&topic_defs, &AdminOptions::new())
            .await
            .map_err(|e| anyhow!("Topic creation RPC failed: {e}"))?;

        for res in results {
            match res {
                Ok(name) => log::info!("âœ… Topic created: {}", name),
                Err((name, err)) if err.to_string().contains("TopicAlreadyExists") => {
                    log::debug!("ğŸ” Topic [{}] already exists, skipping", name);
                }
                Err((name, err)) => {
                    log::warn!("âš ï¸ Topic [{}] creation failed: {}", name, err);
                }
            }
        }

        Ok(())
    }
}
