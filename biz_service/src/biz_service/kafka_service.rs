use anyhow::anyhow;
use common::config::KafkaConfig;
use once_cell::sync::OnceCell;
use prost::Message;
use rdkafka::ClientConfig;
use rdkafka::admin::{AdminClient, AdminOptions, NewTopic, TopicReplication};
use rdkafka::producer::{FutureProducer, FutureRecord};
use serde::Serialize;
use std::fmt;
use std::sync::Arc;
use std::time::Duration;
#[repr(u8)]
#[derive(Clone, Copy, Debug, PartialEq, Eq)]
pub enum KafkaMessageType {
    FriendMsg = 1,

}
#[derive(Clone)]
pub struct KafkaService {
    producer: FutureProducer,
    config: KafkaConfig,
}
impl fmt::Debug for KafkaService {
    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {
        f.debug_struct("KafkaService").field("config", &self.config).finish()
    }
}
impl KafkaService {
    pub fn new(cfg: KafkaConfig) -> Self {
        let producer = ClientConfig::new().set("bootstrap.servers", &cfg.brokers).create().expect("Kafka producer init failed");

        KafkaService { producer, config: cfg }
    }

    /// åˆå§‹åŒ–ï¼šåˆ›å»º topicsï¼Œç„¶åæ³¨å†Œå•ä¾‹
    pub async fn init(cfg: &KafkaConfig) {
        Self::create_topics_or_exit(&cfg.brokers, &[(&cfg.topic_single, 3, 1), (&cfg.topic_group, 2, 1)]).await;

        let instance = Self::new(cfg.clone());
        SERVICE.set(Arc::new(instance)).expect("KafkaService already initialized");
    }
    /// å¼‚æ­¥åˆ›å»ºå¤šä¸ª topicï¼Œå¦‚æœå·²å­˜åœ¨åˆ™é€€å‡ºç¨‹åº
    pub async fn create_topics_or_exit(brokers: &str, topics: &[(&str, i32, i32)]) {
        let admin: AdminClient<_> = ClientConfig::new().set("bootstrap.servers", brokers).create().expect("Failed to create Kafka AdminClient");

        let topic_defs: Vec<_> = topics.iter().map(|(name, part, rep)| NewTopic::new(*name, *part, TopicReplication::Fixed(*rep))).collect();

        let results = admin.create_topics(&topic_defs, &AdminOptions::new()).await.expect("Kafka topic creation failed");

        for result in results {
            match result {
                Ok(name) => println!("âœ… Created topic: {}", name),
                Err((name, err)) if err.to_string().contains("TopicAlreadyExists") => {
                    if err.to_string().contains("TopicAlreadyExists") {
                        println!("ğŸ” Topic [{}] already exists, skipping", name);
                        continue;
                    }
                }
                Err((name, err)) => {
                    eprintln!("âŒ Failed to create topic [{}]: {}", name, err);
                    std::process::exit(1);
                }
            }
        }
    }

    /// å‘é€æ¶ˆæ¯(json)
    pub async fn send<T: Serialize>(&self, value: &T, key: &str, topic: &str) -> Result<(i32, i64), anyhow::Error> {
        let payload = serde_json::to_string(value)?;
        let record = FutureRecord::to(topic).payload(&payload).key(key);

        // å¢åŠ åˆç†è¶…æ—¶æ—¶é—´ä»¥åˆ©ç”¨æ‰¹å¤„ç†æœºåˆ¶
        let timeout = Duration::from_millis(50); // å¯è°ƒä¼˜

        match self.producer.send(record, timeout).await {
            Ok((partition, offset)) => {
                log::debug!("Kafka OK => topic={}, partition={}, offset={}", topic, partition, offset);
                Ok((partition, offset))
            }
            Err((err, _)) => {
                log::error!("Kafka å‘é€å¤±è´¥: {:?}", err);
                Err(anyhow!(err))
            }
        }
    }
    /// protoä¸“æœ‰ç¼–ç ä¸è§£ç 
    pub async fn send_proto<M: Message>(&self, value: &M, key: &str, topic: &str) -> Result<(i32, i64), anyhow::Error> {
        let payload = value.encode_to_vec();
        let record = FutureRecord::to(topic).payload(&payload).key(key);

        let timeout = Duration::from_millis(50); // å¯æ ¹æ®ååé‡å’Œå»¶è¿Ÿä¼˜åŒ–

        match self.producer.send(record, timeout).await {
            Ok((partition, offset)) => {
                log::debug!("Kafka Protobuf å‘é€æˆåŠŸ => topic={}, partition={}, offset={}", topic, partition, offset);
                Ok((partition, offset))
            }
            Err((err, _)) => {
                log::error!("Kafka Protobuf å‘é€å¤±è´¥: {:?}", err);
                Err(anyhow!(err))
            }
        }
    }
    ///äºŒè¿›åˆ¶
    pub async fn send_proto_byte<M: Message>(&self, value: &M, msg_type: KafkaMessageType, key: &str, topic: &str) -> Result<(i32, i64), anyhow::Error> {
        let mut buf = Vec::with_capacity(value.encoded_len() + 1);
        buf.push(msg_type as u8);
        value.encode(&mut buf)?;

        let record = FutureRecord::to(topic)
            .payload(&buf)
            .key(key);

        let timeout = Duration::from_millis(50);

        match self.producer.send(record, timeout).await {
            Ok((partition, offset)) => {
                log::debug!("Kafka äºŒè¿›åˆ¶å‘é€æˆåŠŸ: topic={}, partition={}, offset={}", topic, partition, offset);
                Ok((partition, offset))
            }
            Err((err, _)) => {
                log::error!("Kafka å‘é€å¤±è´¥: {:?}", err);
                Err(anyhow!(err))
            }
        }
    }

    /// è·å–å•ä¾‹
    pub fn get() -> Arc<Self> {
        SERVICE.get().expect("KafkaService is not initialized").clone()
    }
}

static SERVICE: OnceCell<Arc<KafkaService>> = OnceCell::new();
